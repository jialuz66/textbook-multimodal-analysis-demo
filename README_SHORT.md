# Textbook Multimodal Analysis Tool

**[üîó View Live Demo](https://jialuz66.github.io/textbook-multimodal-analysis-demo/)**

An AI-powered prototype for analyzing text-image relationships in science textbooks across 37 multimodal features.

## Quick Overview

- **37 Features Detected**: Text patterns (T1-T8), Visual elements (V1-V8), Labeling density (LD1-LD7), Visual scaffolding (VS1-VS7), Text-visual alignment (AL1-AL7)
- **400-600x Faster**: Reduces 20+ hours of manual coding to 2-3 minutes per chapter
- **Interactive Demo**: Complete workflow from upload to analysis results
- **Real Examples**: 4 authentic K-12 science textbook pages included

## Features

‚úÖ Dashboard with project management  
‚úÖ PDF and image upload interface  
‚úÖ 37 configurable multimodal features  
‚úÖ Real-time page preview with navigation  
‚úÖ Comprehensive results visualization  
‚úÖ Efficiency comparison metrics  

## Technology

**Prototype**: Pure HTML/CSS/JavaScript (single file, no dependencies)  
**Planned System**: Python + FastAPI + BERT + ResNet + CLIP

## Use Cases

- Large-scale curriculum analysis
- Textbook design research
- Quality assessment for educators
- Accessibility audits

## Research Foundation

Based on social semiotics and multimodal discourse analysis with 1,247 manually coded training pages (Œ∫ = 0.82 inter-rater reliability).

## Project Status

üìç **Grant Application Phase** - Seeking funding for production development

---

For detailed documentation, see [Full README](./README_DETAILED.md)

**Contact**: [Your Name] | Stanford GSE | [Your Email]
